"""
üî¨ Sistema de An√°lisis Profundo - 3ra Capa
Analiza conversaciones peri√≥dicamente para detectar patrones, emociones y cumplimiento de objetivos
SE EJECUTA SOLO PERI√ìDICAMENTE (cada 50 conversaciones o semanalmente) para ahorrar recursos
"""

import asyncio
import json
import logging
import os
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Optional

logger = logging.getLogger(__name__)


class EmotionType(Enum):
    """Emociones detectadas en conversaciones"""

    SATISFIED = "satisfied"  # Cliente satisfecho
    FRUSTRATED = "frustrated"  # Cliente frustrado
    CONFUSED = "confused"  # Cliente confundido
    ANGRY = "angry"  # Cliente enojado
    EXCITED = "excited"  # Cliente emocionado
    NEUTRAL = "neutral"  # Cliente neutral
    SUSPICIOUS = "suspicious"  # Cliente sospecha que es bot
    IMPATIENT = "impatient"  # Cliente impaciente


class ObjectiveStatus(Enum):
    """Estado de cumplimiento de objetivo"""

    ACHIEVED = "achieved"  # Objetivo logrado
    FAILED = "failed"  # Objetivo no logrado
    PARTIAL = "partial"  # Objetivo parcialmente logrado
    ABANDONED = "abandoned"  # Cliente abandon√≥
    IN_PROGRESS = "in_progress"  # A√∫n en progreso


@dataclass
class ConversationAnalysis:
    """Resultado de an√°lisis profundo de conversaci√≥n"""

    session_id: str
    contact: str
    analyzed_at: datetime

    # An√°lisis de emoci√≥n
    primary_emotion: EmotionType
    emotion_confidence: float  # 0-1
    emotion_timeline: list[dict[str, Any]]  # C√≥mo cambi√≥ la emoci√≥n

    # Detecci√≥n de sospecha de bot
    bot_suspicion_detected: bool
    bot_suspicion_indicators: list[str]
    bot_suspicion_severity: float  # 0-1

    # An√°lisis de objetivo
    objective_status: ObjectiveStatus
    objective_name: Optional[str]
    objective_achieved_at: Optional[datetime]
    success_factors: list[str]
    failure_factors: list[str]

    # Calidad de conversaci√≥n
    conversation_quality_score: float  # 0-100
    response_naturalness_score: float  # 0-100
    customer_satisfaction_score: float  # 0-100

    # Insights y recomendaciones
    insights: list[str]
    recommended_actions: list[str]
    warnings: list[str]


class DeepAnalyzer:
    """Analizador profundo de conversaciones usando LLM"""

    def __init__(self, multi_llm=None, analytics_manager=None):
        self.multi_llm = multi_llm
        self.analytics = analytics_manager

        # Configuraci√≥n
        self.enabled = os.getenv("DEEP_ANALYSIS_ENABLED", "true").lower() == "true"
        self.trigger_every_n_conversations = int(os.getenv("DEEP_ANALYSIS_TRIGGER_CONVERSATIONS", "50"))
        self.trigger_every_n_days = int(os.getenv("DEEP_ANALYSIS_TRIGGER_DAYS", "7"))

        # Estado
        self.conversations_since_last_analysis = 0
        self.last_analysis_date = None
        self.analysis_history = []

        logger.info("üî¨ DeepAnalyzer inicializado")
        logger.info(f"  Trigger cada {self.trigger_every_n_conversations} conversaciones")
        logger.info(f"  Trigger cada {self.trigger_every_n_days} d√≠as")

    def should_trigger_analysis(self) -> bool:
        """Determina si es momento de ejecutar an√°lisis profundo"""
        if not self.enabled:
            return False

        # Trigger por cantidad de conversaciones
        if self.conversations_since_last_analysis >= self.trigger_every_n_conversations:
            logger.info(f"üî¨ Trigger: {self.conversations_since_last_analysis} conversaciones")
            return True

        # Trigger por tiempo
        if self.last_analysis_date:
            days_since = (datetime.now() - self.last_analysis_date).days
            if days_since >= self.trigger_every_n_days:
                logger.info(f"üî¨ Trigger: {days_since} d√≠as desde √∫ltimo an√°lisis")
                return True

        return False

    def record_conversation_end(self):
        """Registra que una conversaci√≥n termin√≥"""
        self.conversations_since_last_analysis += 1

    async def analyze_conversation(
        self, session_id: str, contact: str, messages: list[dict[str, Any]], business_objectives: Optional[list[str]] = None
    ) -> ConversationAnalysis:
        """
        Analiza una conversaci√≥n completa en profundidad
        SE LLAMA SOLO CUANDO ES NECESARIO, no en cada mensaje
        """
        try:
            logger.info(f"üî¨ Analizando conversaci√≥n: {session_id}")

            # Construir contexto para el LLM
            conversation_text = self._format_conversation(messages)
            analysis_prompt = self._build_analysis_prompt(conversation_text, business_objectives)

            # Usar LLM para an√°lisis (preferir modelos de razonamiento)
            if self.multi_llm:
                response = await self.multi_llm.generate_response(
                    messages=[{"role": "user", "content": analysis_prompt}],
                    prefer_reasoning=True,  # xAI Grok, o1-preview, etc.
                )

                if response["success"]:
                    analysis_data = self._parse_llm_analysis(response["message"])
                else:
                    logger.error(f"‚ùå Error en an√°lisis LLM: {response.get('error')}")
                    analysis_data = self._create_fallback_analysis()
            else:
                analysis_data = self._create_fallback_analysis()

            # Crear objeto de an√°lisis
            analysis = ConversationAnalysis(
                session_id=session_id, contact=contact, analyzed_at=datetime.now(), **analysis_data
            )

            # Guardar an√°lisis
            self.analysis_history.append(analysis)

            # Registrar en analytics si est√° disponible
            if self.analytics:
                self._save_to_analytics(analysis)

            logger.info(
                f"‚úÖ An√°lisis completado: {analysis.primary_emotion.value}, calidad={analysis.conversation_quality_score:.1f}"
            )

            return analysis

        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis profundo: {e}")
            return self._create_error_analysis(session_id, contact, str(e))

    async def analyze_batch(
        self, conversations: list[dict[str, Any]], business_objectives: Optional[list[str]] = None
    ) -> list[ConversationAnalysis]:
        """
        Analiza m√∫ltiples conversaciones en batch
        Usa cuando se triggerea el an√°lisis peri√≥dico
        """
        logger.info(f"üî¨ Analizando batch de {len(conversations)} conversaciones")

        results = []
        for conv in conversations:
            analysis = await self.analyze_conversation(
                session_id=conv.get("session_id"),
                contact=conv.get("contact"),
                messages=conv.get("messages", []),
                business_objectives=business_objectives,
            )
            results.append(analysis)

            # Peque√±a pausa para no saturar API
            await asyncio.sleep(0.5)

        # Resetear contador
        self.conversations_since_last_analysis = 0
        self.last_analysis_date = datetime.now()

        # Generar reporte agregado
        aggregate_report = self._generate_aggregate_report(results)
        logger.info(f"üìä Reporte agregado: {json.dumps(aggregate_report, indent=2)}")

        return results

    def _format_conversation(self, messages: list[dict[str, Any]]) -> str:
        """Formatea conversaci√≥n para an√°lisis"""
        lines = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            msg.get("timestamp", "")

            prefix = "Cliente:" if role == "user" else "Asistente:"
            lines.append(f"{prefix} {content}")

        return "\n".join(lines)

    def _build_analysis_prompt(self, conversation: str, business_objectives: Optional[list[str]]) -> str:
        """Construye prompt para an√°lisis profundo"""

        objectives_text = ""
        if business_objectives:
            objectives_text = "\n".join([f"- {obj}" for obj in business_objectives])
            objectives_section = f"""
OBJETIVOS DE NEGOCIO:
{objectives_text}
"""
        else:
            objectives_section = ""

        prompt = f"""Eres un analista experto en conversaciones de atenci√≥n al cliente. Analiza la siguiente conversaci√≥n EN PROFUNDIDAD.

CONVERSACI√ìN:
{conversation}
{objectives_section}

Tu an√°lisis debe incluir (responde en formato JSON):

1. **An√°lisis de Emoci√≥n:**
   - primary_emotion: (satisfied/frustrated/confused/angry/excited/neutral/suspicious/impatient)
   - emotion_confidence: (0.0-1.0)
   - emotion_timeline: lista de {{message_index, emotion, trigger}} mostrando c√≥mo cambi√≥

2. **Detecci√≥n de Sospecha de Bot:**
   - bot_suspicion_detected: (true/false)
   - bot_suspicion_indicators: lista de frases o patrones que indican sospecha
   - bot_suspicion_severity: (0.0-1.0) qu√© tan seguro est√° el cliente de que es bot

3. **An√°lisis de Objetivo:**
   - objective_status: (achieved/failed/partial/abandoned/in_progress)
   - objective_name: nombre del objetivo detectado o null
   - success_factors: lista de factores que contribuyeron al √©xito
   - failure_factors: lista de factores que causaron fallo

4. **Calidad de Conversaci√≥n:**
   - conversation_quality_score: (0-100) calidad general
   - response_naturalness_score: (0-100) qu√© tan naturales son las respuestas
   - customer_satisfaction_score: (0-100) satisfacci√≥n estimada del cliente

5. **Insights y Recomendaciones:**
   - insights: lista de insights importantes (3-5 puntos)
   - recommended_actions: acciones espec√≠ficas a tomar (3-5 puntos)
   - warnings: advertencias cr√≠ticas si las hay

IMPORTANTE:
- S√© espec√≠fico y honesto
- Si detectas que el bot se revel√≥, m√°rcalo con alta severidad
- Si el objetivo no se cumpli√≥, identifica por qu√©
- Las recomendaciones deben ser ACCIONABLES

Responde SOLO con JSON v√°lido, sin explicaciones adicionales."""

        return prompt

    def _parse_llm_analysis(self, llm_response: str) -> dict[str, Any]:
        """Parsea respuesta del LLM a formato estructurado"""
        try:
            # Intentar parsear como JSON
            # Limpiar respuesta (a veces el LLM agrega markdown)
            clean_response = llm_response.strip()
            if clean_response.startswith("```json"):
                clean_response = clean_response[7:]
            if clean_response.startswith("```"):
                clean_response = clean_response[3:]
            if clean_response.endswith("```"):
                clean_response = clean_response[:-3]
            clean_response = clean_response.strip()

            data = json.loads(clean_response)

            # Convertir enums
            data["primary_emotion"] = EmotionType(data.get("primary_emotion", "neutral"))
            data["objective_status"] = ObjectiveStatus(data.get("objective_status", "in_progress"))

            # Parsear fecha si existe
            if data.get("objective_achieved_at"):
                data["objective_achieved_at"] = datetime.fromisoformat(data["objective_achieved_at"])

            return data

        except Exception as e:
            logger.error(f"‚ùå Error parseando an√°lisis LLM: {e}")
            logger.debug(f"Respuesta LLM: {llm_response[:500]}...")
            return self._create_fallback_analysis()

    def _create_fallback_analysis(self) -> dict[str, Any]:
        """Crea an√°lisis b√°sico cuando LLM falla"""
        return {
            "primary_emotion": EmotionType.NEUTRAL,
            "emotion_confidence": 0.5,
            "emotion_timeline": [],
            "bot_suspicion_detected": False,
            "bot_suspicion_indicators": [],
            "bot_suspicion_severity": 0.0,
            "objective_status": ObjectiveStatus.IN_PROGRESS,
            "objective_name": None,
            "objective_achieved_at": None,
            "success_factors": [],
            "failure_factors": ["An√°lisis autom√°tico no disponible"],
            "conversation_quality_score": 50.0,
            "response_naturalness_score": 50.0,
            "customer_satisfaction_score": 50.0,
            "insights": ["An√°lisis manual requerido"],
            "recommended_actions": ["Revisar conversaci√≥n manualmente"],
            "warnings": ["Sistema de an√°lisis autom√°tico no disponible"],
        }

    def _create_error_analysis(self, session_id: str, contact: str, error: str) -> ConversationAnalysis:
        """Crea an√°lisis de error"""
        return ConversationAnalysis(
            session_id=session_id,
            contact=contact,
            analyzed_at=datetime.now(),
            primary_emotion=EmotionType.NEUTRAL,
            emotion_confidence=0.0,
            emotion_timeline=[],
            bot_suspicion_detected=False,
            bot_suspicion_indicators=[],
            bot_suspicion_severity=0.0,
            objective_status=ObjectiveStatus.IN_PROGRESS,
            objective_name=None,
            objective_achieved_at=None,
            success_factors=[],
            failure_factors=[f"Error en an√°lisis: {error}"],
            conversation_quality_score=0.0,
            response_naturalness_score=0.0,
            customer_satisfaction_score=0.0,
            insights=[],
            recommended_actions=["Revisar error en logs"],
            warnings=[f"Error cr√≠tico: {error}"],
        )

    def _save_to_analytics(self, analysis: ConversationAnalysis):
        """Guarda an√°lisis en sistema de analytics"""
        try:
            # Aqu√≠ se guardar√≠a en base de datos o analytics
            # Por ahora solo log
            logger.info(f"üíæ Guardando an√°lisis de {analysis.session_id}")
        except Exception as e:
            logger.error(f"‚ùå Error guardando an√°lisis: {e}")

    def _generate_aggregate_report(self, analyses: list[ConversationAnalysis]) -> dict[str, Any]:
        """Genera reporte agregado de m√∫ltiples an√°lisis"""
        if not analyses:
            return {}

        # Estad√≠sticas de emociones
        emotion_counts = {}
        for analysis in analyses:
            emotion = analysis.primary_emotion.value
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

        # Estad√≠sticas de objetivos
        objective_counts = {}
        for analysis in analyses:
            status = analysis.objective_status.value
            objective_counts[status] = objective_counts.get(status, 0) + 1

        # Detecci√≥n de sospechas de bot
        bot_suspicions = sum(1 for a in analyses if a.bot_suspicion_detected)

        # Promedios de calidad
        avg_quality = sum(a.conversation_quality_score for a in analyses) / len(analyses)
        avg_naturalness = sum(a.response_naturalness_score for a in analyses) / len(analyses)
        avg_satisfaction = sum(a.customer_satisfaction_score for a in analyses) / len(analyses)

        # Advertencias cr√≠ticas
        all_warnings = []
        for analysis in analyses:
            all_warnings.extend(analysis.warnings)

        # Insights m√°s comunes
        all_insights = []
        for analysis in analyses:
            all_insights.extend(analysis.insights)

        return {
            "total_conversations": len(analyses),
            "analyzed_at": datetime.now().isoformat(),
            "emotions": emotion_counts,
            "objectives": objective_counts,
            "bot_suspicions": {"total": bot_suspicions, "percentage": (bot_suspicions / len(analyses)) * 100},
            "quality_metrics": {
                "avg_conversation_quality": round(avg_quality, 2),
                "avg_response_naturalness": round(avg_naturalness, 2),
                "avg_customer_satisfaction": round(avg_satisfaction, 2),
            },
            "critical_warnings": list(set(all_warnings)),
            "top_insights": list(set(all_insights))[:10],
        }

    def get_stats(self) -> dict[str, Any]:
        """Estad√≠sticas del analizador"""
        return {
            "enabled": self.enabled,
            "conversations_since_last_analysis": self.conversations_since_last_analysis,
            "last_analysis_date": self.last_analysis_date.isoformat() if self.last_analysis_date else None,
            "total_analyses": len(self.analysis_history),
            "trigger_conversations": self.trigger_every_n_conversations,
            "trigger_days": self.trigger_every_n_days,
            "should_trigger": self.should_trigger_analysis(),
        }


# Instancia global
deep_analyzer = DeepAnalyzer()
