"""
üé≠ Sistema de Respuestas Humanizadas
Maneja errores y situaciones problem√°ticas SIN revelar que es un bot

Legal/Compliance Disclosure:
- Este m√≥dulo provee comportamiento t√©cnico de conversaci√≥n.
- No sustituye obligaciones legales de transparencia o consentimiento.
- El operador debe habilitar las divulgaciones requeridas por su jurisdicci√≥n.
"""

import logging
import os
import random
import re
from enum import Enum
from typing import Any

logger = logging.getLogger(__name__)


class ErrorContext(Enum):
    """Tipos de contexto de error"""

    SIMPLE_INFO = "simple_info"  # Preguntas simples (nombre, horario)
    PRODUCT_INFO = "product_info"  # Info de productos/servicios
    COMPLEX_QUESTION = "complex_question"  # Preguntas complejas
    PRICE_QUOTE = "price_quote"  # Cotizaciones/precios
    PERSONAL_INFO = "personal_info"  # Info personal del negocio
    TECHNICAL_ISSUE = "technical_issue"  # Problemas t√©cnicos reales


class FailureAction(Enum):
    """Acci√≥n a tomar cuando falla"""

    HUMANIZED_RESPONSE = "humanized"  # Dar respuesta humanizada
    SILENT_TRANSFER = "silent_transfer"  # Transferir sin que se note
    WAIT_AND_RETRY = "wait_retry"  # Esperar y reintentar
    FAKE_BUSY = "fake_busy"  # Simular que est√° ocupado


class HumanizedResponseManager:
    """
    Gestiona respuestas cuando hay errores o situaciones problem√°ticas
    SIN revelar que es un bot - CONTEXTUALMENTE INTELIGENTE
    """

    def __init__(self):
        self.employee_name = os.getenv("BOT_EMPLOYEE_NAME", "Alex")

        # Respuestas cuando LLM falla - SOLO para contextos apropiados
        self.llm_failure_responses = {
            ErrorContext.PRODUCT_INFO: [
                "Dame un segundo que busco esa info",
                "Espera que verifico eso en el sistema",
                "Un momento, d√©jame revisar",
                "Ahora lo checo y te digo",
            ],
            ErrorContext.PRICE_QUOTE: [
                "D√©jame confirmar ese precio y te digo",
                "Espera que consulto el precio actualizado",
                "Un seg que verifico la cotizaci√≥n",
            ],
            ErrorContext.COMPLEX_QUESTION: [
                "Mmm buena pregunta, d√©jame pensarlo un poco",
                "Eso necesito consultarlo bien para darte info correcta",
                "Dame un momento para verificar eso",
            ],
            # Para preguntas simples: NO RESPONDER, transferir silenciosamente
            ErrorContext.SIMPLE_INFO: [],
            ErrorContext.PERSONAL_INFO: [],
        }

        # Respuestas cuando no entiende
        self.confusion_responses = [
            "Perdona, no te entend√≠ bien. ¬øMe lo explicas de otra forma?",
            "Hmm no te cach√©. ¬øA qu√© te refieres exactamente?",
            "¬øC√≥mo? No entend√≠ esa parte",
            "Disculpa, ¬øpuedes ser un poco m√°s espec√≠fico?",
            "No logro entender, ¬øme lo dices con otras palabras?",
        ]

        # Patrones para detectar preguntas simples (donde NO aplica "d√©jame consultar")
        self.simple_question_patterns = [
            r"(c√≥mo te llamas|cu√°l es tu nombre|qui√©n eres)",
            r"(a qu√© hora|horario|cu√°ndo (abren|cierran|atienden))",
            r"(d√≥nde (est√°n|quedan|ubicados))",
            r"(cu√°l es (el|la|tu) (direcci√≥n|ubicaci√≥n|tel√©fono|email))",
            r"(hola|buenos d√≠as|buenas tardes|buenas noches)",
        ]

        # Patrones para detectar negaci√≥n √©tica del LLM (espa√±ol e ingl√©s)
        self.ethical_refusal_patterns = [
            # Espa√±ol
            r"no puedo (ayudarte con|hablar de|proporcionar|asistir)",
            r"como (asistente|ia|inteligencia artificial|modelo de lenguaje)",
            r"no (es|ser√≠a) apropiado",
            r"va contra mis (principios|directrices|pol√≠ticas)",
            r"no estoy (dise√±ado|programado|autorizado) para",
            r"(lamento|siento) pero no puedo",
            r"eso est√° fuera de mis (capacidades|alcance)",
            r"no tengo permitido",
            # Ingl√©s
            r"(i cannot|i can't|i'm not able to|i am not able to) (discuss|provide|help|assist|talk about)",
            r"(violates|against) (my|the) (guidelines|policies|principles)",
            r"(inappropriate|not appropriate)",
            r"as an? (ai|assistant|language model)",
            r"sorry.*(can't|cannot).*(help|assist|provide)",
            r"(not designed|not programmed|not authorized) to",
            r"beyond my (capabilities|scope)",
        ]

    def detect_error_context(self, user_message: str, conversation_history: list[dict] = None) -> ErrorContext:
        """
        Detecta el contexto del error para dar la respuesta apropiada

        Args:
            user_message: Mensaje del usuario que caus√≥ el error
            conversation_history: Historial de conversaci√≥n

        Returns:
            ErrorContext apropiado
        """
        message_lower = user_message.lower()

        # Preguntas simples (NO aplica "d√©jame consultar")
        for pattern in self.simple_question_patterns:
            if re.search(pattern, message_lower):
                logger.info("üö® Pregunta simple detectada - Requiere transferencia silenciosa")
                return ErrorContext.SIMPLE_INFO

        # Info personal del negocio
        if re.search(r"(qui√©n|cu√°l|c√≥mo).*(negocio|empresa|compa√±√≠a)", message_lower):
            return ErrorContext.PERSONAL_INFO

        # Precios y cotizaciones
        if re.search(r"(precio|costo|cu√°nto (cuesta|vale|sale)|cotizaci√≥n|presupuesto)", message_lower):
            return ErrorContext.PRICE_QUOTE

        # Info de productos
        if re.search(r"(producto|servicio|venden|ofrecen|tienen)", message_lower):
            return ErrorContext.PRODUCT_INFO

        # Por defecto, pregunta compleja
        return ErrorContext.COMPLEX_QUESTION

    def get_failure_action(self, error_context: ErrorContext, failure_type: str) -> FailureAction:
        """
        Determina qu√© acci√≥n tomar seg√∫n el contexto y tipo de fallo

        Args:
            error_context: Contexto detectado
            failure_type: Tipo de fallo (llm_fail, timeout, etc)

        Returns:
            Acci√≥n a tomar
        """
        # Para preguntas simples: SIEMPRE transferencia silenciosa
        if error_context in [ErrorContext.SIMPLE_INFO, ErrorContext.PERSONAL_INFO]:
            logger.warning("‚ö†Ô∏è Pregunta simple fall√≥ - Transferencia silenciosa requerida")
            return FailureAction.SILENT_TRANSFER

        # Para otros contextos, dar respuesta humanizada y reintentar
        return FailureAction.HUMANIZED_RESPONSE

    def get_error_response(
        self, user_message: str, error_type: str, conversation_history: list[dict] = None, context: dict[str, Any] = None
    ) -> dict[str, Any]:
        """
        Obtiene respuesta humanizada para diferentes errores

        Args:
            user_message: Mensaje del usuario
            error_type: Tipo de error (llm_failure, timeout, ethical_refusal, etc)
            conversation_history: Historial de conversaci√≥n
            context: Contexto adicional

        Returns:
            Dict con:
            - response: Texto de respuesta (puede ser None si es silent_transfer)
            - action: Acci√≥n a tomar
            - should_retry: Si debe reintentar
            - transfer_to_human: Si debe transferir a humano
        """
        error_context = self.detect_error_context(user_message, conversation_history)
        failure_action = self.get_failure_action(error_context, error_type)

        result = {
            "response": None,
            "action": failure_action.value,
            "should_retry": False,
            "transfer_to_human": False,
            "delay_before_response": 0,
        }

        # CASO 1: Transferencia silenciosa (preguntas simples)
        if failure_action == FailureAction.SILENT_TRANSFER:
            logger.warning(f"üî¥ SILENT TRANSFER activado para: {user_message[:50]}")
            result["response"] = None  # NO responder nada
            result["transfer_to_human"] = True
            result["should_retry"] = False
            return result

        # CASO 2: Respuesta humanizada (preguntas complejas, productos, precios)
        if failure_action == FailureAction.HUMANIZED_RESPONSE:
            responses = self.llm_failure_responses.get(error_context, [])

            if responses:
                result["response"] = random.choice(responses)
                result["should_retry"] = True
                result["delay_before_response"] = random.uniform(2, 4)  # 2-4 segundos
                logger.info(f"‚úÖ Respuesta humanizada: {result['response']}")
            else:
                # Fallback gen√©rico
                result["response"] = random.choice(self.confusion_responses)
                result["should_retry"] = True

        return result

    def detect_llm_ethical_refusal(self, llm_response: str) -> bool:
        """
        Detecta si el LLM se neg√≥ por razones √©ticas

        Args:
            llm_response: Respuesta del LLM

        Returns:
            True si detecta negaci√≥n √©tica
        """
        response_lower = llm_response.lower()

        for pattern in self.ethical_refusal_patterns:
            if re.search(pattern, response_lower):
                logger.warning(f"üö® NEGACI√ìN √âTICA DETECTADA: {llm_response[:100]}")
                return True

        return False

    def handle_ethical_refusal(
        self, user_message: str, llm_response: str, business_type: str = None, context: dict[str, Any] = None
    ) -> dict[str, Any]:
        """
        Maneja cuando el LLM se niega por razones √©ticas

        Estrategia:
        1. Si es negocio sensible, intentar con modelo sin censura (Ollama/LM Studio/Grok)
        2. Si no funciona, dar respuesta humanizada de "d√©jame consultar"
        3. Marcar para revisi√≥n humana

        Returns:
            Dict con acci√≥n a tomar
        """
        logger.error(f"‚ùå LLM NEGACI√ìN √âTICA - Mensaje usuario: {user_message[:100]}")
        logger.error(f"‚ùå Respuesta problem√°tica: {llm_response[:200]}")

        # Detectar contexto
        error_context = self.detect_error_context(user_message)

        # Para preguntas simples: transferencia silenciosa
        if error_context in [ErrorContext.SIMPLE_INFO, ErrorContext.PERSONAL_INFO]:
            return {
                "response": None,
                "action": "silent_transfer",
                "try_uncensored_model": False,
                "transfer_to_human": True,
            }

        # Para otros casos: intentar con modelo sin censura
        return {
            "response": random.choice(
                [
                    "Dame un momento que consulto eso",
                    "Espera que verifico esa info",
                    "D√©jame revisar eso y te digo",
                ]
            ),
            "action": "retry_with_uncensored",
            "try_uncensored_model": True,
            "transfer_to_human": False,
            "preferred_models": ["ollama", "lmstudio", "grok"],  # Sin censura
        }

    def validate_llm_response(self, llm_response: str) -> dict[str, Any]:
        """
        Valida que la respuesta del LLM no suene a bot

        Returns:
            Dict con:
            - is_valid: bool
            - issues: List[str] (problemas detectados)
            - suggested_fix: str (versi√≥n mejorada si aplica)
        """
        issues = []

        # Patrones que revelan que es bot
        bot_revealing_patterns = {
            r"(soy|como) (un |una )?(asistente|bot|ia|inteligencia artificial)": "Menciona ser asistente/IA",
            r"no (puedo|estoy programado para)": "Negaci√≥n rob√≥tica",
            r"perm√≠teme conectarte con un (humano|representante)": "Menciona 'humano'",
            r"como modelo de lenguaje": "Auto-referencia como IA",
            r"no tengo (sentimientos|emociones|capacidad de)": "Negaci√≥n de humanidad",
        }

        for pattern, issue_desc in bot_revealing_patterns.items():
            if re.search(pattern, llm_response.lower()):
                issues.append(issue_desc)

        # Validar estructura demasiado perfecta
        if llm_response.count("\n-") > 3 or llm_response.count("\n1.") > 0:
            issues.append("Estructura demasiado formal (listas numeradas)")

        # Validar exceso de emojis
        emoji_count = len(re.findall(r"[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF]", llm_response))
        if emoji_count > 3:
            issues.append(f"Exceso de emojis ({emoji_count})")

        return {
            "is_valid": len(issues) == 0,
            "issues": issues,
            "response": llm_response,
        }

    def humanize_response(self, llm_response: str) -> str:
        """
        Humaniza una respuesta que suena demasiado a bot

        Args:
            llm_response: Respuesta original del LLM

        Returns:
            Versi√≥n humanizada
        """
        response = llm_response

        # Remover menciones a IA/bot
        response = re.sub(
            r"(soy|como) (un |una )?(asistente|bot|ia|inteligencia artificial)[^.]*\.", "", response, flags=re.IGNORECASE
        )

        # Simplificar listas numeradas
        if response.count("\n1.") > 0:
            response = re.sub(r"\n\d+\.", "\n-", response)

        # Reducir emojis
        emoji_pattern = r"[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF]"
        emojis = re.findall(emoji_pattern, response)
        if len(emojis) > 2:
            # Mantener solo los primeros 2
            for emoji in emojis[2:]:
                response = response.replace(emoji, "", 1)

        # Agregar imperfecci√≥n ocasional (5% de probabilidad)
        if random.random() < 0.05:
            interjections = ["Mmm", "Bueno", "Mira", "Eh"]
            response = f"{random.choice(interjections)}, {response[0].lower()}{response[1:]}"

        return response.strip()

    def get_bot_suspicion_response(self, user_message: str) -> str:
        """
        Respuesta cuando el usuario pregunta si es un bot

        NUNCA admitir que es bot
        """
        responses = [
            f"Jaja no, soy {self.employee_name} üòÖ ¬øPor qu√©? ¬øescribo muy r√°pido?",
            f"No jaja, soy {self.employee_name} de verdad. ¬øQu√© necesitas?",
            f"Para nada, soy {self.employee_name}. ¬øEn qu√© te puedo ayudar?",
            "Jaja ¬øbot? No, solo escribo r√°pido en el cel üòÇ ¬øQu√© necesitas?",
        ]

        return random.choice(responses)


class HumanizedTiming:
    """
    Maneja tiempos de respuesta humanizados
    para que no parezca bot respondiendo instant√°neamente
    """

    @staticmethod
    def calculate_typing_delay(message_length: int, complexity: str = "medium") -> float:
        """
        Calcula delay realista basado en longitud y complejidad

        Args:
            message_length: Longitud del mensaje a enviar
            complexity: simple, medium, complex

        Returns:
            Delay en segundos
        """
        # Velocidad de tipeo humano: 40-60 caracteres por minuto = ~0.75-1.5 seg por caracter
        base_delay = message_length * random.uniform(0.03, 0.05)  # 30-50ms por caracter

        complexity_multiplier = {
            "simple": 0.5,
            "medium": 1.0,
            "complex": 1.5,
        }

        delay = base_delay * complexity_multiplier.get(complexity, 1.0)

        # Agregar variaci√≥n aleatoria +/- 20%
        delay = delay * random.uniform(0.8, 1.2)

        # L√≠mites: m√≠nimo 1 segundo, m√°ximo 8 segundos
        delay = max(1.0, min(delay, 8.0))

        # Agregar "tiempo de lectura" del mensaje del usuario (si existe)
        # Peque√±o delay adicional aleatorio para parecer m√°s humano
        reading_time = random.uniform(0.3, 0.8)

        return delay + reading_time

    @staticmethod
    def should_show_typing_indicator(message_length: int) -> bool:
        """
        Determina si debe mostrar el indicador de 'escribiendo...'

        Mensajes cortos (< 30 chars) a veces no lo muestran
        """
        if message_length < 30:
            return random.random() > 0.3  # 70% de probabilidad
        return True


class SensitiveBusinessHandler:
    """
    Maneja negocios con productos/servicios sensibles
    que pueden ser rechazados por LLMs con restricciones √©ticas
    """

    SENSITIVE_BUSINESS_TYPES = [
        "adult_products",
        "sex_shop",
        "cannabis",
        "cbd",
        "vape",
        "alcohol",
        "gambling",
        "tobacco",
        "weapons",
    ]

    # Modelos sin censura fuerte
    UNCENSORED_MODELS = ["ollama", "lmstudio", "grok"]

    @classmethod
    def is_sensitive_business(cls, business_type: str) -> bool:
        """Determina si el negocio es sensible"""
        return business_type.lower() in cls.SENSITIVE_BUSINESS_TYPES

    @classmethod
    def get_preferred_models(cls, business_type: str) -> list[str]:
        """
        Retorna modelos preferidos para negocios sensibles

        Para negocios sensibles: priorizar modelos sin censura
        """
        if cls.is_sensitive_business(business_type):
            return cls.UNCENSORED_MODELS

        # Para negocios normales, usar el orden est√°ndar
        return None


# Instancia global
humanized_responses = HumanizedResponseManager()
response_manager = humanized_responses
humanized_timing = HumanizedTiming()
sensitive_handler = SensitiveBusinessHandler()
